# Fine tuning for Vocal
## TTS Model Pipeline çµè«–
1. speaker01_clipä¸èƒ½åŠ é€å­—ç¨¿ï¼Œé›»è…¦GPUè·‘ä¸å‹•ã€‚
2. æœ‰åŠ é€å­—ç¨¿æ¯”è¼ƒä¸æœƒå‡ºç¾errorçš„ç‹€æ³ã€‚(å¹¾ä¹æ²’æœ‰)
3. æ™‚é–“åˆ‡å‰²15sçš„æ•ˆæœæ¯”25så¥½ã€‚(speaker02_clipçš„æ•ˆæœæ¯”speaker01_clipå¥½)
4. æ‹¿æ‰å¥è™Ÿå…¨ç”¨é€—è™Ÿå¯ä»¥é¿å…æ®µè½åˆæˆçš„é›»éŸ³ï¼Œä½†æ˜¯æœƒæ¯”è¼ƒå®¹æ˜“å‡ºç¾çµå°¾è¿´åœˆçš„ç‹€æ³ã€‚

## æ“ä½œæµç¨‹
### .pyæª”å¾1è·‘åˆ°7ç„¶å¾Œæ¥brezzy voice(æ”¹æª”æ¡ˆè·¯å¾‘)

```bash
#before start
cd ~/Desktop/MIT_test
python3.12 -m venv .venv312
source .venv312/bin/activate
```

```bash
# before step4
export LD_LIBRARY_PATH=`poetry run python -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))'`
```

```bash
# run step6
poetry run python 6_speaker_splitter.py voice_data/vocals/mdx_extra/autobiography/vocals_mono16k.wav voice_data/output/segments_for_splitter.json 
# poetry run python 5_speaker_splitter.py è·¯å¾‘/ä½ çš„éŸ³æª”.wav è·¯å¾‘/ä½ çš„jsonæª”.json
```

```bash
# before brezzy voice
deactivate
git clone https://github.com/mtkresearch/BreezyVoice.git
cd ~/Desktop/MIT_test/BreezyVoice
python3.10 -m venv .venv310
source .venv310/bin/activate
# ä¿®æ”¹ requirements
pip install -r requirements.txt
```

```bash
# run single inference
poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "ä½ å¥½ï¼Œæˆ‘æ˜¯é™³æ–‡èŒœï¼Œå¾ˆé–‹å¿ƒèªè­˜ä½ ã€‚" \
  --output_path "../voice_data/output/result.wav"
```

```bash
# run batch inference
poetry run python3 batch_inference.py \
  --csv_file ./batch_files.csv \
  --speaker_prompt_audio_folder ../voice_data/output \
  --output_audio_folder ../voice_data/output/batch
```

## Test Sample

```bash
#test context
poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "ä¹Ÿæ²’æœ‰ä»€éº¼æŒ‘æˆ°ï¼Œæˆ‘çš„å¤–å©†æ˜¯å°æˆ‘éåº¦è‡ªä¿¡ã€éåº¦è¢’è­·ã€‚æˆ‘å¤–å©†æœ‰å¹¾å€‹å¿ƒç†ï¼Œé›–ç„¶æˆ‘å¹³å¸¸å¯èƒ½ä¸å¤ªæ•™åŠŸèª²ã€å¯èƒ½æœ‰æˆ‘è‡ªå·±çš„ã€å°±æœƒæ´»åœ¨æˆ‘è‡ªå·±çš„å¹»æƒ³ä¸–ç•Œã€‚" \
  --output_path "../voice_data/output/result00.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "åª½åª½èªªå¥¹å¾ˆå®¹æ˜“ç·Šå¼µï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©ã€‚é‚£æ™‚æˆ‘ç™¼ç‡’ï¼Œå¥¹ä¸çŸ¥é“è©²æ€éº¼ç…§é¡§ï¼Œå°±è®“å¤–å©†æ¥æ‰‹ã€‚å¤–å©†èªªæˆ‘æ°´åœŸä¸æœï¼Œå¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­ã€‚å…¶å¯¦å¥¹ä¸€ç›´å¾ˆç–¼æˆ‘ï¼Œæ€•æˆ‘è¢«åª½åª½å¸¶èµ°ã€‚æœ‰æ™‚å€™é‚„æœƒèªªï¼šã€Œæˆ‘å¸¶å¦³å»è²·ç¦®ç‰©ï¼Œä½†å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ã€‚ã€" \
  --output_path "../voice_data/output/result01.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "åª½åª½èªªå¥¹æ˜¯å€‹å¾ˆå®¹æ˜“ nervous çš„äººå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹çš„ first kidã€‚å¥¹é‚£æ™‚å€™ä¸çŸ¥é“æ€éº¼ç…§é¡§æˆ‘ï¼Œå°±è®“å¤–å©†å¹«å¿™ã€‚å¤–å©†èªªæˆ‘æ°´åœŸä¸æœï¼Œå°±å¾èŠ±è“®å¸¶å›å°ä¸­ï¼Œé‚„èªªï¼šã€Œæˆ‘è²·ç¦®ç‰©çµ¦å¦³ï¼Œä½†ä¸èƒ½è·Ÿå¦³åª½è¬›è©±å–”ã€‚ã€" \
  --output_path "../voice_data/output/result02.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "My mom said she was really nervous because I was her first child. When I got sick, she didnâ€™t know how to take care of me, so my grandma stepped in. Grandma thought I couldnâ€™t adjust to the environment, so she brought me back from Hualien to Taichung and took care of me ever since." \
  --output_path "../voice_data/output/result03.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "å—¯â€¦åª½åª½å¥¹èªªå¥¹å¾ˆç·Šå¼µå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©å˜›ã€‚ç„¶å¾Œâ€¦æˆ‘é‚£æ™‚å€™ç™¼ç‡’ï¼Œå¥¹å°±â€¦å—¯ï¼Œä¸çŸ¥é“æ€éº¼è¾¦ï¼Œå°±è®“å¤–å©†ä¾†ç…§é¡§æˆ‘ã€‚å¤–å©†å°±èªªå¯èƒ½æ˜¯æ°´åœŸä¸æœå§ï¼Œå°±å¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­é€™æ¨£ã€‚å¾Œä¾†å¥¹é‚„â€¦æœƒèªªã€Œå¦³ä¹–ä¹–æˆ‘å°±å¸¶å¦³å»è²·è¥ªå­å–”ï¼Œå¯æ˜¯å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ï½ã€" \
  --output_path "../voice_data/output/result04.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "åª½åª½èªªå¥¹å¾ˆå®¹æ˜“ç·Šå¼µå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©é‚£æ™‚æˆ‘ç™¼ç‡’å¥¹ä¸çŸ¥é“è©²æ€éº¼ç…§é¡§å°±è®“å¤–å©†æ¥æ‰‹å¤–å©†èªªæˆ‘æ°´åœŸä¸æœå¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­å…¶å¯¦å¥¹ä¸€ç›´å¾ˆç–¼æˆ‘æ€•æˆ‘è¢«åª½åª½å¸¶èµ°æœ‰æ™‚å€™é‚„æœƒèªªæˆ‘å¸¶å¦³å»è²·ç¦®ç‰©ä½†å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”" \
  --output_path "../voice_data/output/result05.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "æˆ‘æœƒå»è²·Liveé›œèªŒï¼Œç„¶å¾Œæ¯å¤©æ´»åœ¨æˆ‘çš„å¤–å¤ªç©ºï¼Œæƒ³åƒæœ‰ä¸€å¤©æˆ‘è¦è®Šæˆå¤ªç©ºäººï¼Œç„¶å¾Œæˆ‘è¦ï¼Œæ‰€ä»¥æˆ‘å¸¸å¸¸åœ¨æƒ³èªªï¼Œå¦‚æœæˆ‘ç”Ÿåœ¨ç¾åœ‹ã€æˆ–æ˜¯ä¿„åœ‹æˆ‘å¯èƒ½æœƒå»NASAï¼Œä½ çŸ¥é“å—å¤ªç©ºç¸½ç½²ä¸Šç­ï¼Œä½†æ˜¯æˆ‘æ²’æœ‰å¤ªå¿ æ–¼è‡ªå·±OKï¼Œé‚£æˆ‘å°±è¦ºå¾—èªªå¯èƒ½ï¼Œé€™å€‹åœ¨æˆ‘å€‘å°ç£é€™å€‹ç¤¾æœƒä¸æ˜¯å¾ˆpracticalé€™æ¨£ï¼Œé‚£æˆ‘å¤–å©†åªæ˜¯èªªå¥¹åœ¨é€™å€‹ä¸–ç•Œä¸Šå¥¹æ²’æœ‰çµ¦ä½ ä»»ä½•çš„å£“åŠ›ï¼Œå®ƒå·®åˆ¥åœ¨ä»€éº¼åœ°æ–¹å‘¢ï¼Œç¬¬ä¸€å€‹ã€‚" \
  --content_to_synthesize "å—¯åª½åª½å¥¹èªªå¥¹å¾ˆç·Šå¼µå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©å˜›ï¼Œç„¶å¾Œæˆ‘é‚£æ™‚å€™ç™¼ç‡’ï¼Œå¥¹å°±å—¯ï¼Œä¸çŸ¥é“æ€éº¼è¾¦ï¼Œå°±è®“å¤–å©†ä¾†ç…§é¡§æˆ‘ï¼Œå¤–å©†å°±èªªå¯èƒ½æ˜¯æ°´åœŸä¸æœå§ï¼Œå°±å¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­é€™æ¨£ï¼Œå¾Œä¾†å¥¹é‚„æœƒèªªï¼Œå¦³ä¹–ä¹–æˆ‘å°±å¸¶å¦³å»è²·è¥ªå­å–”ï¼Œå¯æ˜¯å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ã€‚" \
  --output_path "../voice_data/output/result06.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker01_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "å—¯åª½åª½å¥¹èªªå¥¹å¾ˆç·Šå¼µå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©å˜›ï¼Œç„¶å¾Œæˆ‘é‚£æ™‚å€™ç™¼ç‡’ï¼Œå¥¹å°±å—¯ï¼Œä¸çŸ¥é“æ€éº¼è¾¦ï¼Œå°±è®“å¤–å©†ä¾†ç…§é¡§æˆ‘ï¼Œå¤–å©†å°±èªªå¯èƒ½æ˜¯æ°´åœŸä¸æœå§ï¼Œå°±å¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­é€™æ¨£ï¼Œå¾Œä¾†å¥¹é‚„æœƒèªªï¼Œå¦³ä¹–ä¹–æˆ‘å°±å¸¶å¦³å»è²·è¥ªå­å–”ï¼Œå¯æ˜¯å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ã€‚" \
  --output_path "../voice_data/output/result07.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker02_clip.wav" \
  --speaker_prompt_text_transcription "æˆ‘æœƒå»è²·Liveé›œèªŒï¼Œç„¶å¾Œæ¯å¤©æ´»åœ¨æˆ‘çš„å¤–å¤ªç©ºï¼Œæƒ³åƒæœ‰ä¸€å¤©æˆ‘è¦è®Šæˆå¤ªç©ºäººï¼Œç„¶å¾Œæˆ‘è¦ï¼Œæ‰€ä»¥æˆ‘å¸¸å¸¸åœ¨æƒ³èªªï¼Œå¦‚æœæˆ‘ç”Ÿåœ¨ç¾åœ‹ã€æˆ–æ˜¯ä¿„åœ‹æˆ‘å¯èƒ½æœƒå»NASAï¼Œä½ çŸ¥é“å—å¤ªç©ºç¸½ç½²ä¸Šç­ï¼Œä½†æ˜¯æˆ‘æ²’æœ‰å¤ªå¿ æ–¼è‡ªå·±OKï¼Œé‚£æˆ‘å°±è¦ºå¾—èªªã€‚" \
  --content_to_synthesize "å—¯åª½åª½å¥¹èªªå¥¹å¾ˆç·Šå¼µå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©å˜›ï¼Œç„¶å¾Œæˆ‘é‚£æ™‚å€™ç™¼ç‡’ï¼Œå¥¹å°±å—¯ï¼Œä¸çŸ¥é“æ€éº¼è¾¦ï¼Œå°±è®“å¤–å©†ä¾†ç…§é¡§æˆ‘ï¼Œå¤–å©†å°±èªªå¯èƒ½æ˜¯æ°´åœŸä¸æœå§ï¼Œå°±å¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­é€™æ¨£ï¼Œå¾Œä¾†å¥¹é‚„æœƒèªªï¼Œå¦³ä¹–ä¹–æˆ‘å°±å¸¶å¦³å»è²·è¥ªå­å–”ï¼Œå¯æ˜¯å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ã€‚" \
  --output_path "../voice_data/output/result08.wav"

poetry run python3 single_inference.py \
  --speaker_prompt_audio_path "../voice_data/output/speaker02_clip.wav" \
  --speaker_prompt_text_transcription "" \
  --content_to_synthesize "å—¯åª½åª½å¥¹èªªå¥¹å¾ˆç·Šå¼µå•¦ï¼Œå› ç‚ºæˆ‘æ˜¯å¥¹ç¬¬ä¸€å€‹å°å­©å˜›ï¼Œç„¶å¾Œæˆ‘é‚£æ™‚å€™ç™¼ç‡’ï¼Œå¥¹å°±å—¯ï¼Œä¸çŸ¥é“æ€éº¼è¾¦ï¼Œå°±è®“å¤–å©†ä¾†ç…§é¡§æˆ‘ï¼Œå¤–å©†å°±èªªå¯èƒ½æ˜¯æ°´åœŸä¸æœå§ï¼Œå°±å¾èŠ±è“®å¸¶æˆ‘å›å°ä¸­é€™æ¨£ï¼Œå¾Œä¾†å¥¹é‚„æœƒèªªï¼Œå¦³ä¹–ä¹–æˆ‘å°±å¸¶å¦³å»è²·è¥ªå­å–”ï¼Œå¯æ˜¯å¦³ä¸èƒ½è·Ÿå¦³åª½åª½è¬›è©±å–”ã€‚" \
  --output_path "../voice_data/output/result09.wav"
```

# Fine tuning for tone
## Easy DataSet æ“ä½œæµç¨‹
### .pyæª”è·‘1-2-3-4.1-4.2-5.1(æ”¹æª”æ¡ˆè·¯å¾‘)(æ•ˆæœä¸ä½³)

```bash
#before start
cd ~/Desktop/MIT_test
source .venv312/bin/activate
```

```bash
# before step4.1
deactivate
python3.9 -m venv .venv309w
source .venv309w/bin/activate
pip install -U openai-whisper
pip install git+https://github.com/openai/whisper.git 
pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git
sudo apt update && sudo apt install ffmpeg
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
pip install setuptools-rust
```

```bash
# before step4.2
deactivate
python3.10 -m venv .venv310p
source .venv310p/bin/activate
pip install pyannote.audio
# ä¿®æ”¹speaker number
```

```bash
# before step5.1
deactivate
source .venv312/bin/activate
```

### .pyæª”è·‘1-2-3-4pw-5-8-9(æ”¹æª”æ¡ˆè·¯å¾‘)(æ•ˆæœæœ€å¥½)

```bash
#before start
cd ~/Desktop/MIT_test
source .venv312/bin/activate
```

```bash
# before step4pw
deactivate
git clone https://github.com/yinruiqing/pyannote-whisper.git
cd ~/Desktop/MIT_test/pyannote-whisper
pyenv local 3.9.13
python -m venv .venv309
source .venv309/bin/activate
pip install -r ../requirements_pw.txt
pip install -e .

deactivate
cd ~/Desktop/MIT_test/pyannote-whisper
source .venv309/bin/activate
```

```bash
# before step5
deactivate
cd ~/Desktop/MIT_test
source .venv312/bin/activate
```

## Dataset æ¸…ç†ç›®æ¨™

```bash
cd ~/Desktop/MIT_test/tone_clean
```

1. ç°¡é«”è½‰ç¹é«” convert_language.py
2. åŠ æ¨™é»èˆ‡æ–·å¥
3. åˆªé™¤èªè€…åˆ†é›¢éŒ¯èª¤é‡è¤‡èªå¥
4. å°æ¯ç­†å›ç­”é€²è¡Œåˆ†é¡ 4_devide_group.py 4_top2vec.py
5. æ¸…é™¤ä½å“è³ªæˆ–éŒ¯èª¤çš„èªæ–™
6. å¾®èª¿è³‡æ–™ä¸è¦éé•·
7. å°åŒä¸€å€‹å›ç­”ç”¢ç”Ÿå¤šå€‹ä¸åŒå•é¡Œï¼ˆåè¦†å•ç­”è¨“ç·´ï¼‰
8. æ·»åŠ åŸå§‹æ¨¡å‹è¨“ç·´å¥

### 1ï¸âƒ£ ç°¡é«”è½‰ç¹é«”
ğŸ¯ ç›®çš„ï¼šçµ±ä¸€èªè¨€æ ¼å¼ç‚ºå°ç£ç”¨å­—ï¼Œé¿å…è¨“ç·´èªæ°£æ··äº‚
ğŸ“Œ å­ä»»å‹™ï¼š
å°‡æ‰€æœ‰ç°¡é«”å­—è½‰ç‚ºç¹é«”ï¼ˆä½¿ç”¨å°ç£å¸¸è¦‹ç”¨èªï¼‰

ğŸ› ï¸ å·¥å…·ï¼š
opencc-python-reimplementedï¼Œè½‰æ›æ¨¡å¼ï¼šs2twp.json

âœ… è‡ªå‹•åŒ–ï¼šâœ… æ‰¹æ¬¡è™•ç† answer æ¬„ä½å³å¯
ğŸ“ å‚™è¨»ï¼š
å¯åŠ å…¥ç°¡é«”è©åµæ¸¬æ©Ÿåˆ¶ï¼Œè·³éå·²æ˜¯ç¹é«”çš„è³‡æ–™

### 2ï¸âƒ£ åŠ æ¨™é»èˆ‡æ–·å¥
ğŸ¯ ç›®çš„ï¼šä½¿å›ç­”æ›´æ¥è¿‘çœŸå¯¦å£èªèªèª¿ï¼Œæå‡èªæ°£å­¸ç¿’æ•ˆæœ
ğŸ“Œ å­ä»»å‹™ï¼š
è‡ªå‹•ç‚ºå›ç­”å¥å­è£œæ¨™é»èˆ‡æ–·å¥ï¼ˆå¦‚é€—è™Ÿã€å¥è™Ÿã€å•è™Ÿï¼‰

ğŸ› ï¸ å·¥å…·ï¼š
deep-punctuation-zh

å¯æ­é… jieba åšè©åˆ‡å‰²

âœ… è‡ªå‹•åŒ–ï¼šâœ… æ”¯æ´æ‰¹æ¬¡è™•ç†
ğŸ“ å‚™è¨»ï¼š
æ¨¡å‹é è¨“ç·´èªæ–™å¤§å¤šå«æ¨™é» â†’ è‹¥ç„¡æ¨™é»å°‡å½±éŸ¿ fine-tune æ•ˆæœ

### 3ï¸âƒ£ åˆªé™¤èªè€…åˆ†é›¢éŒ¯èª¤é‡è¤‡èªå¥
ğŸ¯ ç›®çš„ï¼šå»é™¤èªæ–™é›œè¨Šï¼Œé¿å…æ¨¡å‹å­¸åˆ°éŒ¯èª¤èªèª¿æˆ–é‡è¤‡è©±è¡“
ğŸ“Œ å­ä»»å‹™ï¼š
æ¯”å°æ¯ç­†å›ç­”èˆ‡ä¸Šä¸‹æ–‡æ˜¯å¦é«˜åº¦ç›¸ä¼¼ï¼Œå»é™¤æ™‚é–“æ¥è¿‘ä¸”é‡è¤‡çš„å¥å­

ğŸ› ï¸ å·¥å…·ï¼š
Python difflib.SequenceMatcher

fuzzywuzzyï¼ˆæ¨¡ç³Šå­—ä¸²æ¯”å°ï¼‰

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯è¨­å®šç›¸ä¼¼åº¦é–¾å€¼è‡ªå‹•éæ¿¾
ğŸ“ å‚™è¨»ï¼š
å»ºè­°ä¿ç•™è¼ƒé•·çš„ç‰ˆæœ¬ï¼Œåˆªé™¤é‡è¤‡ä¸”çŸ­çš„å…§å®¹

### 4ï¸âƒ£ å°æ¯ç­†å›ç­”é€²è¡Œåˆ†é¡
ğŸ¯ ç›®çš„ï¼šæ¨™è¨˜èªæ°£é¢¨æ ¼é¡å‹ï¼Œæ–¹ä¾¿å¾ŒçºŒåˆ†çµ„è¨“ç·´æˆ–ç”Ÿæˆå•é¡Œ
ğŸ“Œ å­ä»»å‹™ï¼š
ç‚ºå›ç­”æ‰“ä¸Šèªæ°£é¡åˆ¥ï¼Œä¾‹å¦‚ï¼šã€Œæ„Ÿæ€§ã€ã€ã€Œè©•è«–ã€ã€ã€Œåå•ã€ã€ã€Œå†·éœæ•˜è¿°ã€ã€ã€Œä¸»æŒèªã€

ğŸ› ï¸ å·¥å…·ï¼š
ä½¿ç”¨ GPT-4 / ChatGPT APIï¼Œåˆ†é¡ prompt å¯å®šç¾©èªæ°£åˆ†é¡é‚è¼¯

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯æ‰¹æ¬¡åˆ†é¡ï¼Œå„²å­˜ç‚º type æ¬„ä½
ğŸ“ å‚™è¨»ï¼š
å¯é…åˆé¸æ“‡æ€§è¨“ç·´ç­–ç•¥ï¼Œä¾‹å¦‚åƒ…è¨“ç·´è©•è«–é¡å›ç­”

### 5ï¸âƒ£ æ¸…é™¤ä½å“è³ªæˆ–éŒ¯èª¤çš„èªæ–™
ğŸ¯ ç›®çš„ï¼šé¿å…è¨“ç·´è³‡æ–™å‡ºç¾èªç—…ã€éèªæ°£å¥æˆ–ç©ºç™½å…§å®¹
ğŸ“Œ å­ä»»å‹™ï¼š
ç§»é™¤éçŸ­ï¼ˆ< 20 å­—ï¼‰ã€éèªå¥ï¼ˆã€Œå—¯ã€ã€ã€Œå‘µå‘µã€ï¼‰ã€æ‹¼éŸ³æˆ–äº‚ç¢¼

æª¢æŸ¥æ ¼å¼æ˜¯å¦åˆæ³•ï¼ˆJSON çµæ§‹å®Œæ•´ï¼‰

ğŸ› ï¸ å·¥å…·ï¼š
Python é•·åº¦åˆ¤æ–· + é—œéµè©æ’é™¤ + json æª¢æŸ¥

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯æ‰¹æ¬¡åˆªé™¤æˆ–æ¨™è¨˜
ğŸ“ å‚™è¨»ï¼š
å¯é¡å¤–è¼¸å‡ºã€Œåˆªé™¤è³‡æ–™è¡¨ã€ä¾›äººå·¥è¤‡æŸ¥

### 6ï¸âƒ£ å¾®èª¿è³‡æ–™ä¸è¦éé•·
ğŸ¯ ç›®çš„ï¼šé¿å…è¨“ç·´æ™‚è¼¸å…¥é•·åº¦è¶…é token é™åˆ¶ã€é€ æˆèªæ°£å´©å£
ğŸ“Œ å­ä»»å‹™ï¼š
å° instruction + output é•·åº¦åŠ ç¸½å¾Œï¼Œé™åˆ¶æ–¼ 1024~2048 tokens å…§

ğŸ› ï¸ å·¥å…·ï¼š
Python + tokenizerï¼ˆä¾‹å¦‚ transformers.AutoTokenizer.from_pretrained("Qwen")ï¼‰

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯è‡ªå‹•è£åˆ‡ã€ç§»é™¤ã€è­¦å‘Š
ğŸ“ å‚™è¨»ï¼š
å¤ªé•·çš„å›ç­”æœƒå°è‡´ attention ä¸é›†ï¼Œé¢¨æ ¼å­¸ç¿’ä¸é›†ä¸­

### 7ï¸âƒ£ å°åŒä¸€å€‹å›ç­”ç”¢ç”Ÿå¤šå€‹ä¸åŒå•é¡Œï¼ˆåè¦†å•ç­”è¨“ç·´ï¼‰
ğŸ¯ ç›®çš„ï¼šå¼·åŒ–èªæ°£ç©©å®šæ€§ï¼Œä¸ç®¡å•æ³•æ€éº¼è®Šï¼Œå›ç­”èªæ°£ä¸€è‡´
ğŸ“Œ å­ä»»å‹™ï¼š
å°åŒä¸€ç­†å›ç­”ç”¢å‡º 2~3 ç¨®ä¸åŒä½†èªæ„ç›¸é—œçš„æå•ï¼ˆparaphraseï¼‰

ğŸ› ï¸ å·¥å…·ï¼š
ChatGPT APIã€paraphrasing modelï¼ˆå¦‚ Pegasusã€BART ä¸­æ–‡åŒ–ï¼‰

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯æ‰¹æ¬¡è™•ç†ï¼ˆå¤šå°ä¸€ï¼‰
ğŸ“ å‚™è¨»ï¼š
è«‹ä¿ç•™å›ç­”ä¸è®Šï¼Œinstruction è®ŠåŒ–ï¼Œæ‰èƒ½å­¸å‡ºèªæ°£ç©©å®š

### 8ï¸âƒ£ æ·»åŠ åŸå§‹æ¨¡å‹è¨“ç·´å¥ï¼ˆQwen instruction anchorï¼‰
ğŸ¯ ç›®çš„ï¼šé¿å…æ¨¡å‹å¤±å»åŸºæœ¬å°è©±èƒ½åŠ›ã€ä¿æŒèªè¨€çµæ§‹æ­£å¸¸
ğŸ“Œ å­ä»»å‹™ï¼š
å¾ Qwen2.5 åŸå§‹ instruction-tuning è³‡æ–™é›†ä¸­æ“·å–ä¸­æ€§ç¯„ä¾‹ï¼ˆå¦‚ï¼šç¤¾äº¤ã€å•ç­”ã€å°çŸ¥è­˜ï¼‰

ğŸ› ï¸ å·¥å…·ï¼š
Hugging Face Qwen2.5 SFT è³‡æ–™ï¼ˆæˆ–æˆ‘å¯å¹«ä½ æå–ï¼‰

âœ… è‡ªå‹•åŒ–ï¼šâœ… å¯æŠ½æ¨£ä¸¦åŠ å…¥åˆ°åŸå§‹ dataset ä¸­ï¼ˆæ··åˆæ¯”ä¾‹å»ºè­° 5â€“10%ï¼‰
ğŸ“ å‚™è¨»ï¼š
å¯ä½œç‚ºèªæ°£ anchorï¼Œä¹Ÿèƒ½é é˜²éæ“¬åˆ

## Llama-Factory æ“ä½œæµç¨‹
### ç”¨chatgptç”ŸæˆQAç„¶å¾Œ.pyæª”è·‘10

http://10.100.1.124:7860
