import json
import torch
import numpy as np
from sentence_transformers import SentenceTransformer, util

# === è·¯å¾‘è¨­å®š ===
GROUPED_JSON_PATH = "output/bertopic11.json"

# === è¼‰å…¥ç¾¤çµ„è³‡æ–™ï¼ˆæ¯çµ„æ˜¯ä¸€å€‹ä¸»é¡Œï¼‰===
with open(GROUPED_JSON_PATH, "r", encoding="utf-8") as f:
    grouped = json.load(f)

print(f"å…±è¼‰å…¥ {len(grouped)} çµ„ä¸»é¡Œ")

# === åˆå§‹åŒ– embedding æ¨¡å‹ ===
embedding_model = SentenceTransformer("shibing624/text2vec-base-chinese")
# shibing624/text2vec-base-chinese
# uer/sbert-base-chinese-nli

# === è¨ˆç®—æ¯çµ„ä¸»é¡Œçš„å¹³å‡å‘é‡ ===
topic_mean_vectors = {}
for group_label, sentences in grouped.items():
    if len(sentences) == 0:
        continue
    embeddings = embedding_model.encode(sentences, convert_to_tensor=True)
    mean_vec = torch.mean(embeddings, dim=0)
    topic_mean_vectors[group_label] = mean_vec

print("å·²å®Œæˆæ‰€æœ‰ä¸»é¡Œçš„å¹³å‡å‘é‡å»ºç«‹")

# === âœ… Top-N ç›¸ä¼¼ä¸»é¡Œæ¯”å°å‡½å¼ ===
def find_top_n_topics(input_sentence: str, top_n=5):
    input_vec = embedding_model.encode(input_sentence, convert_to_tensor=True)
    similarity_scores = []

    for label, mean_vec in topic_mean_vectors.items():
        sim = util.cos_sim(input_vec, mean_vec).item()
        similarity_scores.append((label, sim))

    similarity_scores.sort(key=lambda x: x[1], reverse=True)

    print(f"\nè¼¸å…¥å¥å­ï¼š{input_sentence}")
    print(f"ğŸ” ç›¸ä¼¼åº¦æœ€é«˜çš„å‰ {top_n} çµ„ä¸»é¡Œï¼š\n")
    for i, (label, score) in enumerate(similarity_scores[:top_n]):
        print(f"{i+1:>2}. {label}ï¼ˆç›¸ä¼¼åº¦ï¼š{score:.4f}ï¼‰")

    return similarity_scores[:top_n]

# === ğŸ§ª æ¸¬è©¦ç”¨ ===
if __name__ == "__main__":
    test_sentence = "å¯ä»¥åˆ†äº«ä½ é¤Šç‹—çš„ç¶“é©—å—ï¼Ÿ"
    top_matches = find_top_n_topics(test_sentence, top_n=5)